<html>
  <head>
    <meta charset="utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>关于框式设备的一些小知识 | Gridea</title>
<link rel="shortcut icon" href="https://behemothes.github.io/Behemothes//favicon.ico?v=1586791623736">
<link href="https://cdn.jsdelivr.net/npm/remixicon@2.3.0/fonts/remixicon.css" rel="stylesheet">
<link rel="stylesheet" href="https://behemothes.github.io/Behemothes//styles/main.css">
<link rel="alternate" type="application/atom+xml" title="关于框式设备的一些小知识 | Gridea - Atom Feed" href="https://behemothes.github.io/Behemothes//atom.xml">
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Droid+Serif:400,700">



    <meta name="description" content="一些基本知识
框式设备组成
以框式交换机为例，框式由以下几个组件组成：

机框
主控板
接口板
交换网板

在谈到很多协议时我们会说到转控分离，即网络设备的转发平面、控制平面分离开来，现在新潮的SDN就是典型的转控分离。
谈SDN几乎必谈转..." />
    <meta name="keywords" content="技术杂谈" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.0/katex.min.css">
    <script src="https://cdn.bootcss.com/highlight.js/9.12.0/highlight.min.js"></script>
  </head>
  <body>
    <div class="main">
      <div class="main-content">
        <div class="site-header">
  <a href="https://behemothes.github.io/Behemothes/">
  <img class="avatar" src="https://behemothes.github.io/Behemothes//images/avatar.png?v=1586791623736" alt="">
  </a>
  <h1 class="site-title">
    Gridea
  </h1>
  <p class="site-description">
    温故而知新
  </p>
  <div class="menu-container">
    
      
        <a href="https://behemothes.github.io/Behemothes/" class="menu" target="_blank">
          首页
        </a>
      
    
      
        <a href="https://behemothes.github.io/Behemothes/archives" class="menu">
          归档
        </a>
      
    
      
        <a href="https://behemothes.github.io/Behemothes/tags" class="menu">
          标签
        </a>
      
    
  </div>
  <div class="social-container">
    
      
    
      
    
      
    
      
    
      
    
  </div>
</div>

        <div class="post-detail">
          <article class="post">
            <h2 class="post-title">
              关于框式设备的一些小知识
            </h2>
            <div class="post-info">
              <span>
                2020-04-13
              </span>
              <span>
                19 min read
              </span>
              
                <a href="https://behemothes.github.io/Behemothes/tag/ERd1sKPdu/" class="post-tag">
                  # 技术杂谈
                </a>
              
            </div>
            
            <div class="post-content-wrapper">
              <div class="post-content">
                <h3 id="一些基本知识">一些基本知识</h3>
<h4 id="框式设备组成">框式设备组成</h4>
<p>以框式交换机为例，框式由以下几个组件组成：</p>
<ol>
<li>机框</li>
<li>主控板</li>
<li>接口板</li>
<li>交换网板</li>
</ol>
<p>在谈到很多协议时我们会说到转控分离，即网络设备的转发平面、控制平面分离开来，现在新潮的SDN就是典型的转控分离。</p>
<p>谈SDN几乎必谈转控分离。</p>
<p>对于盒式设备我们很难直观地看到所谓的设备转发平面、控制平面，整个设备就是一个盒子，转、控两平面都集成在盒子内部。</p>
<p>但对于框式设备，我们可以“清楚”地看到设备的转发平面、控制平面：</p>
<ol>
<li>转发平面：由接口板、交换网板组成</li>
<li>控制平面：主控板</li>
</ol>
<p>不过这种简单的划分方法其实并不严谨，如对于接口板而言，其上也存在着处理一些协议报文的芯片，一些我们传统上定义的控制平面做的事，部分也在接口板在上完成了。</p>
<h4 id="各组件之间的连接">各组件之间的连接</h4>
<figure data-type="image" tabindex="1"><img src="http://www.behemoth.icu/img/20200412232510.png" alt="[P1]" loading="lazy"></figure>
<p>框式交换机各组件之间的连接逻辑图如上。</p>
<p>接口板、主控板、交换网板都插在机框上，机框内存在内部接口，这些内部接口和接口板、主控板、交换网板相互连接，机框内部存在将各个槽位上接口相互连接的内部连接线。</p>
<p>接口板、主控板、交换网板之间的通信通过机框提供的接口、内部连接线完成。</p>
<p>这里就有框式设备的一个坑。</p>
<h4 id="报文在框式设备内部转发">报文在框式设备内部转发</h4>
<p>对于框式设备转发报文，业务报文走向如下：</p>
<figure data-type="image" tabindex="2"><img src="http://www.behemoth.icu/img/20200412232525.png" alt="P2" loading="lazy"></figure>
<p>接口板进入-&gt;交换网板-&gt;接口板出</p>
<p>交换网板负责在接口板之间进行报文的转发。</p>
<h5 id="转控分离">转控分离</h5>
<p>在这个过程中可以看到并没有主控板什么事，了解现在网络设备转发的可能都知道，高端一些的网络设备都是所谓的“硬转发”，即转发表项下发在接口板的快速转发芯片中，报文进入接口板直接转发了，根本没有在控制平面查询任何表项。</p>
<p>注意上面我说的转发表项不是传统意义上的三层路由表（RIB：routing information base）、二层的MAC地址表。</p>
<p>以三层转发为例，设备在完成路由学习、路由计算之后生成RIB，根据RIB设备会生成一个FIB（forwarding information base），基本长这样：</p>
<pre><code class="language-shell">Destination/Mask   Nexthop         Flag  TimeStamp     Interface      TunnelID
10.0.35.3/32       10.0.24.2       DGHU  t[71]         GE0/0/0        0x0
10.0.24.0/24       10.0.24.4       U     t[24]         GE0/0/0        0x0
10.0.2.0/24        10.0.24.2       DGU   t[71]         GE0/0/0        0x0
10.0.23.0/24       10.0.24.2       DGU   t[71]         GE0/0/0        0x0
10.0.12.0/24       10.0.24.2       DGU   t[71]         GE0/0/0        0x0
10.0.35.0/24       10.0.24.2       DGU   t[71]         GE0/0/0        0x0
10.0.3.0/24        10.0.24.2       DGU   t[71]         GE0/0/0        0x0
10.0.1.0/24        10.0.24.2       DGU   t[71]         GE0/0/0        0x0
10.0.5.0/24        10.0.24.2       DGU   t[71]         GE0/0/0        0x0
</code></pre>
<p>FIB相比较于路由表区别：</p>
<p>FIB表中nexthop必定是直连的下一跳，路由表中的nexthop可能还不是直连的，比如手动配置的静态路由、从BGP邻居学习过来的路由nexthop地址不在IGP路由表中，这些都需要进行路由迭代计算出直连的下一跳。</p>
<p>用图大概表述下FIB转发过程：</p>
<figure data-type="image" tabindex="3"><img src="http://www.behemoth.icu/img/20200412232606.png" alt="P3" loading="lazy"></figure>
<p>FIB表在接口板直接完成了对报文的转发，而FIB生成来自于主控板上的RIB，主控板生成FIB之后下发到接口板，之后转发时就没主控板什么事，同时主控板是否繁忙对转发也不会存在影响，这就是典型的转控分离。</p>
<figure data-type="image" tabindex="4"><img src="http://www.behemoth.icu/img/20200412232631.png" alt="P4" loading="lazy"></figure>
<h5 id="硬转发">硬转发</h5>
<p>细心想一下，FIB表只是完成了表项存储在接口板上，如果接口板还需要查找这个FIB表，那似乎每次转发还需要查询表项，这距离所谓的快速“硬件转发”貌似还有一些差距。</p>
<p>是的。</p>
<p>实际“硬件转发”时FIB表项并不是存储在接口板的CPU中，转发报文并不需要查询接口板的CPU。</p>
<p>FIB表项的相关信息直接存储在接口的转发芯片中，转发芯片直接依据内存中FIB表项相关信息进行转发。</p>
<p>有兴趣的可以看下下面一段内容：</p>
<figure data-type="image" tabindex="5"><img src="http://www.behemoth.icu/img/20200412232646.png" alt="P5" loading="lazy"></figure>
<p><em>在这里我们能够看到目的地址和目的地址的子网掩码分别是0xa000200和0xffffff00，对应的十进制就是10.0.0.2和255.255.255.0。但是通过该图，我只能看到目的地址和子网掩码，如何去该目的我还是一无所知。</em></p>
<p><em>这时就需要查看该前缀对应VN中的内容，上图中给出了VN的索引号即Index号，所以就要查看该索引号的VN的详细内容。使用下面的命令来查看：</em></p>
<figure data-type="image" tabindex="6"><img src="http://www.behemoth.icu/img/20200412232655.png" alt="P6" loading="lazy"></figure>
<p><em>通过上图可以看到VN的具体信息，他指明了ADJEntry的内存位置，下一条的地址，权重，标签等信息。<strong>值得注意的是这里只有去往目的地的下一条地址，却没有出接口。</strong></em></p>
<p><em>于是，我再找一下ADJ的信息，如下图显示</em></p>
<figure data-type="image" tabindex="7"><img src="http://www.behemoth.icu/img/20200412232709.png" alt="p7" loading="lazy"></figure>
<p><em>这里终于看到了一些信息，这里看到了该接口的ADJ4信息中包含VN的序列号，描述了该接口转发状态，该接口是去往10.0.0.2的出接口。</em></p>
<h5 id="快速转发">快速转发</h5>
<p>后续添加</p>
<h3 id="一些你可能不知道的知识">一些你可能不知道的知识</h3>
<h4 id="没有交换网板的框式设备">没有交换网板的框式设备</h4>
<p>并不是所有的框式设备都有交换网板，一些框式设备主控板集成了交换网板的功能。</p>
<figure data-type="image" tabindex="8"><img src="http://www.behemoth.icu/img/20200412232724.png" alt="P8" loading="lazy"></figure>
<p>从上图可以看出来，一些框式设备主控和交换网板集成在了一起，那这样所有业务报文的转发都必然需要经过主控板。</p>
<figure data-type="image" tabindex="9"><img src="http://www.behemoth.icu/img/20200412232738.png" alt="P9" loading="lazy"></figure>
<h4 id="hw的css2-1n主控备份">HW的CSS2 1+N主控备份</h4>
<p>一个和主控板集成交换网板相关的内容。</p>
<p>HW对于框式交换机二虚一的技术叫做CSS（Cluster Switch System），CSS还分为传统CSS以及CSS2。</p>
<p>CSS2支持一个所谓的“1+N主控备份“：两个框里只要一个有一个主控板正常工作，两个框的接口板就都可以正常转发。</p>
<p>而传统CSS做不到，为啥呢？</p>
<p>因为传统CSS是在主控板集成交换网板的交换机上使用的技术。</p>
<p>了解交换机多虚一技术的话都应该了解，目前见到的多虚一技术在交换机之间都存在着所谓的“虚拟化专用线缆”，这里是在聊CSS，我们就用CSS里的叫法：集群线缆。对于主控板集成交换网板的框式设备来说，集群线缆连接的位置只能是主控板或者是接口板。</p>
<figure data-type="image" tabindex="10"><img src="http://www.behemoth.icu/img/20200412232754.png" alt="P10" loading="lazy"></figure>
<p>集群线缆通过主控板连接：当一个框内主控板全部故障，接口板之间的流量无法通过本框内的主控板转发，同时因为集群线缆在主控板，此时已经丢失了跨框转发流量的能力，无法进行跨框转发。</p>
<figure data-type="image" tabindex="11"><img src="http://www.behemoth.icu/img/20200412232808.png" alt="P11" loading="lazy"></figure>
<p>集群线缆通过接口板连接：当一个框内主控板全部故障，别的接口板与该接口板之间的通信中断，理论上除了连接集群线缆的这个接口板自身还能通过集群线缆跨框转发流量，其余的全部都GG。</p>
<figure data-type="image" tabindex="12"><img src="http://www.behemoth.icu/img/20200412232826.png" alt="P12" loading="lazy"></figure>
<p>而对于主控板、交换网板独立的框式交换机而言，集群线缆可以连接在交换网板上，一个框内的主控板全部故障，无论是本框内接口板之间的流量还是跨框的流量，都可以正常转发。同时控制层面还有另外一个框内的主控板可用，所以可以实现两个框内只要有一个主控板正常工作，整个CSS2内的两个框转发平面、控制平面都可以正常工作，即所谓的“1+N主控备份”。</p>
<p>所以通过以上内容，主控板集成交换网板的劣势大家应该能看出来：</p>
<ol>
<li>主控板故障直接影响设备转发，挂掉一个主控板，接口板之间的转发通道就少了一个，转发性能影响很大。</li>
<li>即便做堆叠、集群、IRF之类的交换机虚拟化技术，一个框内的正常主控板还是至少要有一个，不然框之间没有任何连接，控制平面还是挂掉。</li>
</ol>
<p><strong>其实以上问题的本质是：主控板、交换网板本来分别属于控制平面、转发平面，两种板卡的功能被集成到一个板卡上，一个板卡同时承担转发、控制平面的工作，其故障必然导致两个平面都受到影响，本来框式设备将转、控分离了，为了节省成本这种设计又把产品倒退了。。</strong></p>
<h4 id="板卡之间的连线问题">板卡之间的连线问题</h4>
<p>在基本知识里我提到了：“接口板、主控板、交换网板都插在机框上，机框内存在内部接口，这些内部接口和接口板、主控板、交换网板相互连接，机框内部存在将各个槽位连接的内部连接线。”</p>
<p>机框内连线承载了板卡之间的通信，下图讲解了逻辑上的连接。</p>
<figure data-type="image" tabindex="13"><img src="http://www.behemoth.icu/img/20200412232510.png" alt="P1" loading="lazy"></figure>
<p>在上图里我用蓝色线缆表示接口板与主控板之间的连线，是不是看了这个图大家觉得接口板1、2、3与主控板之间的连线都是完全相同的，或者说带宽相同吧？</p>
<p>答案是很有可能不相同。</p>
<p>回忆下我之前说的内容:&quot;机框内存在内部接口，这些内部接口和接口板、主控板、交换网板相互连接。”</p>
<p>所以把逻辑连接图补充得严谨一些应该是下图的样子。</p>
<figure data-type="image" tabindex="14"><img src="http://www.behemoth.icu/img/20200412232906.png" alt="P13" loading="lazy"></figure>
<p>接口板、主控板（集成了交换网板的功能）插在不同的slot（槽位）上，一般框式交换机的主控板slot固定，其它的slot为接口板、交换网板使用。</p>
<p>内部接口固定在Slot上，固定型号的框式设备，内部接口之间的连线固定，即slot之间的连线固定，理想状态是各个slot之间的连线都是完全相同的：带宽相同。</p>
<p>但是实际情况是，slot之间的连线可能并不相同，比如下面这样：</p>
<figure data-type="image" tabindex="15"><img src="http://www.behemoth.icu/img/20200412232923.png" alt="P14" loading="lazy"></figure>
<p>slot3与slot1、slot2之间的连线拥有比slot4-6与slot1、slot2之间的连线更大带宽，所以可能会出现同样一个接口板插在slot3和slot4上性能不同的情况，如果你遇见过接口板插在不同槽位性能存在差距，嘿嘿，说不定你很幸运地遇见了这样的框式设备。</p>
<p>再想一个问题：接口板所在slot与交换网板所在slot之间的连线一定超过了接口板上所有接口的速率之和吗？</p>
<p>想想为什么会存在内部连线带宽不同的情况，你觉得问题答案会是什么呢？</p>
<figure data-type="image" tabindex="16"><img src="http://www.behemoth.icu/img/20200412232931.png" alt="P15" loading="lazy"></figure>
<p>10G如果够的话为什么会有20G呢，对外宣传这些slot可都是能够满速率的哦。</p>
<h4 id="当框式设备遇见fw板卡">当框式设备遇见FW板卡</h4>
<p>现在很多框式设备都可以插业务板卡，这里的业务板卡不是说接口板，而是：AC（无线控制器）板卡、LB（loadbalance）板卡、FW（firewall）板卡之类的。</p>
<p>AC板卡还好，但是LB板卡、FW板卡需要对框式设备上的业务流量进行负载均衡、安全检查，这就涉及流量牵引问题，如果LB、FW板卡上存在三层接口，来回流量都会经过LB、FW板卡上三层接口转发，那很好，没啥大问题，和普通三层转发没任何区别。</p>
<p>如果框式设备为二层转发流量，那就需要涉及流量牵引，将框式设备来回转发的流量牵引到对应的板卡。</p>
<p><strong>下面以我之前工作过的某厂FW板卡为例讲一些FW板卡的特性，当然并不是所有厂家如下面描述的一样。</strong></p>
<h5 id="框式设备插fw板卡">框式设备插FW板卡</h5>
<p>FW板卡和正常FW一样，转发流量时会检查会话表，如果只是单向流量经过会导致流量无法匹配会话的状态机，从而被丢弃，最典型的例子TCP三次握手：</p>
<figure data-type="image" tabindex="17"><img src="http://www.behemoth.icu/img/20200412232944.png" alt="P16" loading="lazy"></figure>
<p>报文首包[TCP SYN]经过FW1转发，FW为该条流量创建会话表项，同时记录该条会话状态为[SYN Sent]，之后回包[TCP SYN,ACK]并未经过FW1。</p>
<figure data-type="image" tabindex="18"><img src="http://www.behemoth.icu/img/20200412233000.png" alt="P17" loading="lazy"></figure>
<p>当TCP三次握手最后一个报文到达FW1时，FW1检查会话表，发现状态机无法匹配：</p>
<p>此时对应会话的状态为[SYN Sent]，下一个报文应该为[TCP SYN,ACK],但是FW1收到的为[TCP ACK]，状态机匹配失败，报文因此被丢弃。</p>
<p>为此对于FW/FW板卡而言，为保证报文的正常转发需要让来回流量全部经过，不能出现单向路径。</p>
<figure data-type="image" tabindex="19"><img src="http://www.behemoth.icu/img/20200412233010.png" alt="P18" loading="lazy"></figure>
<p>如果框式设备上只有一个FW板卡，引流还不算复杂，使用MQC匹配来回流量，将来回流量都引到FW板卡上。</p>
<figure data-type="image" tabindex="20"><img src="http://www.behemoth.icu/img/20200412233028.png" alt="P19" loading="lazy"></figure>
<p>FW板卡这种业务板卡有明确的内部连接接口号，插在槽位上之后在设备命令行下可以看到内部接口编号，使用MQC将来回流量的出接口设置为该内部接口即可，流量就会通过该接口送达该槽位上的FW板卡。</p>
<figure data-type="image" tabindex="21"><img src="http://www.behemoth.icu/img/20200412233042.png" alt="P20" loading="lazy"></figure>
<p>如果框式设备上存在多个FW板卡，将流量进行分流，分别牵引到不同的FW板卡即可。</p>
<h5 id="转发速率问题">转发速率问题</h5>
<p>当框式交换机插上FW插卡，同时所有业务流量需要经过FW插卡转发时，对于单个业务流而言，经过该框转发的最大速率也会发生变化，这里不仅是因为经过FW插卡多处理一次增加了延迟，另外一个原因是FW插卡转发涉及对报文的四层甚至七层的处理，与二三层硬件快速转发相比较速率差距非常大。</p>
<figure data-type="image" tabindex="22"><img src="http://www.behemoth.icu/img/20200412233054.png" alt="P21" loading="lazy"></figure>
<p>同时由于FW插卡上会话表的存在，来回报文必须在一个FW插卡上处理，单个业务流的速率上限基本就是一个FW插卡的转发速率上限，即便存在多个FW插卡，也无法同时使用多个FW插卡转发一条业务流。</p>
<p>同时即便是一个FW插卡上转发速率也可能存在很大的区别，对于FW插卡而言转发需要CPU参与，这点和AC集中转发模式时处理CAPWAP报文类似。</p>
<p>现在的网络设备也和我们的电脑主机一样CPU都是多核心、多线程的，体现在设备转发时就是存在多个vCPU，每个vCPU都参与转发报文的。</p>
<p>那当一条业务流的报文进入到FW插卡上，多个vCPU会如何协同转发该条业务流呢？</p>
<p>其实和大家非常熟悉的链路聚合一样，也存在基于流分担、基于包分担两种模式：</p>
<figure data-type="image" tabindex="23"><img src="http://www.behemoth.icu/img/20200412233105.png" alt="P22" loading="lazy"></figure>
<ol>
<li>
<p>基于流：一条流被分担到一个固定的vCPU上，所以该条流经过FW插卡转发时速率不会超过一个vCPU的性能上限。</p>
<figure data-type="image" tabindex="24"><img src="http://www.behemoth.icu/img/20200412233117.png" alt="P23" loading="lazy"></figure>
</li>
<li>
<p>基于包：每个数据包会被分担到不同的vCPU上，所以一条流的数据包会被分担到所有的vCPU上进行转发处理，单条业务流经过FW插卡转发的速率是所有vCPU的性能之和。</p>
</li>
</ol>
<p>乍一看使用基于包的模式转发速率会更高啊，一条流能跑满FW的速率，但基于包的转发模式存在一个致命的缺点：每个包在不同的vCPU处理，因此无法保证每个vCPU的处理延时相同，所以报文经过FW插卡之后可能直接乱序了，如下图所示。</p>
<figure data-type="image" tabindex="25"><img src="http://www.behemoth.icu/img/20200412233128.png" alt="P24" loading="lazy"></figure>
<p>报文乱序对于一些业务是完全无法忍受的，如视频会议、语音.......</p>
<p>其实不管是FW插卡还是链路聚合，使用基于包的负载模式都会存在相同的问题，所以实际场景中如果业务对速率要求比较高，但是对是否乱序无所谓可以使用基于包的模式（比如测速给用户看），其它情况下推荐使用基于流，而实际上很多时候网络厂家的默认设置都是基于流。</p>
<p>速率问题不仅是FW插卡如此，构架类似的盒式防火墙也会是相同的情况，所以如果遇见打流测试单条流速率和设备宣传的转发性能相差太多，先别急着喷设备虚标参数（国内防火墙的转发性能参数大家都懂），先问问厂家TAC是不是这设备的转发模式分为基于流和基于包，是不是能调整。</p>
<p>调整为基于包模式之后再去打流测试，结果会快很多，具体快多少看这个设备有多少个逻辑上的vCPU咯，原本用一个vCPU，之后用n个，那结果就是翻n倍咯。</p>
<figure data-type="image" tabindex="26"><img src="http://www.behemoth.icu/img/20200412233135.png" alt="P25" loading="lazy"></figure>
<h5 id="本地优先还是不呢">本地优先还是不呢？</h5>
<p>框式交换机二虚一之后与上下行设备进行跨框链路聚合是很常见的组网，基本为了减少跨框流量的产生，厂家都会默认开启“本地优先”，即链路聚合的出方向流量分担默认都是在本框上的聚合成员接口进行。</p>
<p>那当框式交换机上插了FW插卡，并且来回流量都被MQC牵引到FW插卡上，如果还是本地优先会不会出现什么问题呢？</p>
<p>看下面的例子：</p>
<figure data-type="image" tabindex="27"><img src="http://www.behemoth.icu/img/20200412233154.png" alt="P26" loading="lazy"></figure>
<p>SW3、SW4与二虚一之后的逻辑交换机建立跨设备的链路聚合，SW3使用聚合接口转发负载分担将一条流发送往SW1，SW1在经过本框的FW插卡处理之后依据本地优先转发的原则，将报文从本框发往SW4。</p>
<p>SW4上发送该条流的回向报文，负载分担结果为通过与SW2相连的接口发送，报文到达SW2，SW2跨框还是不跨框呢？</p>
<p>不跨框的话本框上的FW插卡是没有会话表能够匹配该报文的，所以此时如果还是本地优先，结果只能是转发失败，这时就需要关闭本地优先，让流量跨框到SW1，上到SW1的FW插卡处理，再从SW1发往SW3。</p>
<p>这种场景下流量依旧需要保证来回都在一个FW插卡，不然匹配不上会话。SW3、SW4通过聚合接口转发时如何负载分担流量对于框式交换机SW1、2来说完全是未知的，极有可能出现来回流量收发不在一个框上，此时只能让流量跨框回到创建会话的框上。</p>
<h5 id="板卡间会话备份">板卡间会话备份</h5>
<p>对于上一个问题可能有的人会想到在FW板卡上进行会话实时备份。</p>
<figure data-type="image" tabindex="28"><img src="http://www.behemoth.icu/img/20200412233207.png" alt="P27" loading="lazy"></figure>
<p>确实能够解决问题，像HW的HRP一样在板卡间进行备份，在FW板卡之间拉一根线备份会话，但是此时会带来一个新的问题：每个板卡上的会话数目都会变多。</p>
<figure data-type="image" tabindex="29"><img src="http://www.behemoth.icu/img/20200412233239.png" alt="P28" loading="lazy"></figure>
<p>原本一个板卡会话上限10K，从别的板卡备份过来的会话占了4k，该板卡还能新创建的会话只剩6k了，所以实际上该功能很少使用，太耗费性能。想想客户买了2个FW板卡，一个框插一个，然后你开启板卡间会话备份，怎么向客户解释现在两个板卡加在一起会话上限只有一个板卡的规格？</p>
<figure data-type="image" tabindex="30"><img src="http://www.behemoth.icu/img/20200412233248.png" alt="P29" loading="lazy"></figure>
<p>那什么时候可以用板卡间会话备份呢？</p>
<p>板卡为主备备份的时候，这时候无所谓。</p>

              </div>
              <div class="toc-container">
                <ul class="markdownIt-TOC">
<li>
<ul>
<li>
<ul>
<li><a href="#%E4%B8%80%E4%BA%9B%E5%9F%BA%E6%9C%AC%E7%9F%A5%E8%AF%86">一些基本知识</a>
<ul>
<li><a href="#%E6%A1%86%E5%BC%8F%E8%AE%BE%E5%A4%87%E7%BB%84%E6%88%90">框式设备组成</a></li>
<li><a href="#%E5%90%84%E7%BB%84%E4%BB%B6%E4%B9%8B%E9%97%B4%E7%9A%84%E8%BF%9E%E6%8E%A5">各组件之间的连接</a></li>
<li><a href="#%E6%8A%A5%E6%96%87%E5%9C%A8%E6%A1%86%E5%BC%8F%E8%AE%BE%E5%A4%87%E5%86%85%E9%83%A8%E8%BD%AC%E5%8F%91">报文在框式设备内部转发</a>
<ul>
<li><a href="#%E8%BD%AC%E6%8E%A7%E5%88%86%E7%A6%BB">转控分离</a></li>
<li><a href="#%E7%A1%AC%E8%BD%AC%E5%8F%91">硬转发</a></li>
<li><a href="#%E5%BF%AB%E9%80%9F%E8%BD%AC%E5%8F%91">快速转发</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#%E4%B8%80%E4%BA%9B%E4%BD%A0%E5%8F%AF%E8%83%BD%E4%B8%8D%E7%9F%A5%E9%81%93%E7%9A%84%E7%9F%A5%E8%AF%86">一些你可能不知道的知识</a>
<ul>
<li><a href="#%E6%B2%A1%E6%9C%89%E4%BA%A4%E6%8D%A2%E7%BD%91%E6%9D%BF%E7%9A%84%E6%A1%86%E5%BC%8F%E8%AE%BE%E5%A4%87">没有交换网板的框式设备</a></li>
<li><a href="#hw%E7%9A%84css2-1n%E4%B8%BB%E6%8E%A7%E5%A4%87%E4%BB%BD">HW的CSS2 1+N主控备份</a></li>
<li><a href="#%E6%9D%BF%E5%8D%A1%E4%B9%8B%E9%97%B4%E7%9A%84%E8%BF%9E%E7%BA%BF%E9%97%AE%E9%A2%98">板卡之间的连线问题</a></li>
<li><a href="#%E5%BD%93%E6%A1%86%E5%BC%8F%E8%AE%BE%E5%A4%87%E9%81%87%E8%A7%81fw%E6%9D%BF%E5%8D%A1">当框式设备遇见FW板卡</a>
<ul>
<li><a href="#%E6%A1%86%E5%BC%8F%E8%AE%BE%E5%A4%87%E6%8F%92fw%E6%9D%BF%E5%8D%A1">框式设备插FW板卡</a></li>
<li><a href="#%E8%BD%AC%E5%8F%91%E9%80%9F%E7%8E%87%E9%97%AE%E9%A2%98">转发速率问题</a></li>
<li><a href="#%E6%9C%AC%E5%9C%B0%E4%BC%98%E5%85%88%E8%BF%98%E6%98%AF%E4%B8%8D%E5%91%A2">本地优先还是不呢？</a></li>
<li><a href="#%E6%9D%BF%E5%8D%A1%E9%97%B4%E4%BC%9A%E8%AF%9D%E5%A4%87%E4%BB%BD">板卡间会话备份</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>

              </div>
            </div>
          </article>
        </div>

        
          <div class="next-post">
            <div class="next">下一篇</div>
            <a href="https://behemothes.github.io/Behemothes/post/sslvpn-tcp-fang-shi-de-yi-ge-xiao-xi-jie-wen-ti/">
              <h3 class="post-title">
                SSLVPN TCP方式的一个小细节问题
              </h3>
            </a>
          </div>
        

        

        <div class="site-footer">
  Powered by <a href="https://github.com/getgridea/gridea" target="_blank">Gridea</a>
  <a class="rss" href="https://behemothes.github.io/Behemothes//atom.xml" target="_blank">
    <i class="ri-rss-line"></i> RSS
  </a>
</div>

      </div>
    </div>

    <script>
      hljs.initHighlightingOnLoad()

      let mainNavLinks = document.querySelectorAll(".markdownIt-TOC a");

      // This should probably be throttled.
      // Especially because it triggers during smooth scrolling.
      // https://lodash.com/docs/4.17.10#throttle
      // You could do like...
      // window.addEventListener("scroll", () => {
      //    _.throttle(doThatStuff, 100);
      // });
      // Only not doing it here to keep this Pen dependency-free.

      window.addEventListener("scroll", event => {
        let fromTop = window.scrollY;

        mainNavLinks.forEach((link, index) => {
          let section = document.getElementById(decodeURI(link.hash).substring(1));
          let nextSection = null
          if (mainNavLinks[index + 1]) {
            nextSection = document.getElementById(decodeURI(mainNavLinks[index + 1].hash).substring(1));
          }
          if (section.offsetTop <= fromTop) {
            if (nextSection) {
              if (nextSection.offsetTop > fromTop) {
                link.classList.add("current");
              } else {
                link.classList.remove("current");    
              }
            } else {
              link.classList.add("current");
            }
          } else {
            link.classList.remove("current");
          }
        });
      });

    </script>
  </body>
</html>
